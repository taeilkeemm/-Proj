{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN 정리.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4vg030td93j-",
        "outputId": "5d3e7fa6-e019-4638-cef2-66ed6a5707f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-0.9.2-py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 18.8 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning<2.0.0,>=1.2.4\n",
            "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.1,>=0.24 in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (3.2.2)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (1.3.5)\n",
            "Collecting optuna<3.0.0,>=2.3.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (1.10.0+cu111)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pytorch-forecasting) (0.10.2)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (1.4.31)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (4.62.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.3.0->pytorch-forecasting) (1.15.0)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.8.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 23.5 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 30.6 MB/s \n",
            "\u001b[?25hCollecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.10.0.2)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=0.24->pytorch-forecasting) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=0.24->pytorch-forecasting) (1.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (4.11.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.43.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<2.0.0,>=1.2.4->pytorch-forecasting) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (5.4.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (3.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pytorch-forecasting) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pytorch-forecasting) (0.11.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pytorch-forecasting) (0.5.2)\n",
            "Building wheels for collected packages: future, pyperclip\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=4fbd866b14aebfd94a9031c2fe3a279ba94e6054271fc2e07ad86db0ccd8a2eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=fcc24b040274bb4852e0b2f7fdaa46732c155ab1d4d085836885ff2b95141a7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built future pyperclip\n",
            "Installing collected packages: setuptools, multidict, frozenlist, yarl, pyperclip, pbr, asynctest, async-timeout, aiosignal, stevedore, PyYAML, pyDeprecate, Mako, fsspec, cmd2, autopage, aiohttp, torchmetrics, future, colorlog, cmaes, cliff, alembic, pytorch-lightning, optuna, pytorch-forecasting\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.6 PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 alembic-1.7.6 async-timeout-4.0.2 asynctest-0.13.0 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 multidict-6.0.2 optuna-2.10.0 pbr-5.8.1 pyDeprecate-0.3.1 pyperclip-1.8.2 pytorch-forecasting-0.9.2 pytorch-lightning-1.5.10 setuptools-59.5.0 stevedore-3.5.0 torchmetrics-0.7.2 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pytorch-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from time import time \n",
        "from pylab import rcParams\n",
        "from tqdm import tqdm\n",
        "from matplotlib import rc\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "from torch import nn, optim\n",
        "from pytorch_forecasting.metrics import SMAPE\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "lqpyy6D8-J8V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one = pd.read_csv('1등_쓰레기봉투.csv')\n",
        "two = pd.read_csv(\"2등_경유.csv\")\n",
        "three = pd.read_csv(\"3등_보건용마스크(공적판매용).csv\")\n",
        "four = pd.read_csv(\"4등_콘크리트벽돌.csv\")\n",
        "five = pd.read_csv(\"5등_라벨용지.csv\")\n",
        "six = pd.read_csv(\"6등_보건용마스크.csv\")\n",
        "seven = pd.read_csv(\"7등_미장벽돌.csv\")\n",
        "eight = pd.read_csv(\"8등_기타화초.csv\") \n",
        "nine = pd.read_csv(\"9등_강관파일.csv\")\n",
        "ten = pd.read_csv(\"10등_음식물쓰레기처리통.csv\")\n",
        "eleven = pd.read_csv(\"11등_레미콘.csv\")\n",
        "twelve = pd.read_csv(\"12등_금속제창.csv\")"
      ],
      "metadata": {
        "id": "wSpK88rW95m-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one['납품요구접수일자'] =  pd.to_datetime(one['납품요구접수일자'])\n",
        "# one = one.set_index('납품요구접수일자')\n",
        "# one = one.set_index('납품요구접수일자')"
      ],
      "metadata": {
        "id": "2Xiz4DyP-jjK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#월, 년, 주 구하기\n",
        "\n",
        "one['month'] = one.index.month\n",
        "one['year'] = one.index.year\n",
        "one['dayofweek'] = one.index.dayofweek"
      ],
      "metadata": {
        "id": "3lSq0pgR9_mt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 정확도 체크를 위해 smape 값 구하기\n",
        "def smape(pred, target, values = False):\n",
        "  if values : # value 여러개인 list\n",
        "    v = (np.abs(pred - target)) / (np.abs(pred)+np.abs(target))\n",
        "    v = np.mean(v)\n",
        "    \n",
        "  else: #단일 value\n",
        "    v = torch.abs(pred - target) / (torch.abs(pred) + torch.abs(target))\n",
        "\n",
        "  return v*100\n",
        "\n",
        "#train model 만들어서 underfitting, overfitting 확인\n",
        "def train_model(model, train_data, train_labels, val_data=None, val_labels=None, num_epochs=100, verbose = 10):\n",
        "  \n",
        "  optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  train_hist = []\n",
        "  val_hist = []\n",
        "  for t in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for idx, seq in enumerate(train_data): # sample 별 hidden state reset을 해줘야 함 \n",
        "        model.reset_hidden_state()\n",
        "        \n",
        "        y_pred = model(seq)\n",
        "        target = torch.tensor(train_labels[idx])\n",
        "        \n",
        "        loss = smape(y_pred[0].float(), target)\n",
        "        \n",
        "        # loss = loss_fn.loss(y_pred[0].float(), train_labels[idx]) # 1개의 step에 대한 loss\n",
        "\n",
        "        # update weights\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    train_hist.append(epoch_loss / len(train_data))\n",
        "    \n",
        "    if val_data is not None:\n",
        "      with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        val_preds=np.array([])\n",
        "        val_targets=np.array([])\n",
        "        for val_idx, val_seq in enumerate(val_data):\n",
        "            model.reset_hidden_state() #seq 별로 hidden state 초기화 \n",
        "            y_val_pred = model(val_seq)\n",
        "            val_target = torch.tensor(val_labels[val_idx])\n",
        "            \n",
        "            val_preds = np.append(val_preds, np.array([y_val_pred]))\n",
        "            val_targets = np.append(val_targets, np.array([val_target]))\n",
        "\n",
        "        val_smape = smape(val_preds, val_targets, values=True)\n",
        "\n",
        "        val_hist.append(val_smape) # val hist에 추가\n",
        "          \n",
        "      if t % verbose == 0: # epoch loss print\n",
        "          print(f'Epoch {t} train loss: {(epoch_loss / len(train_data)):.3f}%, val loss: {val_smape:.3f}%')\n",
        "            \n",
        "  return model, train_hist, val_hist, val_preds, val_targets\n",
        "  \n",
        "#RNN 모델 구현하기\n",
        "class BTCPredictor1(nn.Module):\n",
        "  def __init__(self, n_features, n_hidden, seq_len, n_layers):\n",
        "    super(BTCPredictor1, self).__init__()\n",
        "    self.n_hidden = n_hidden \n",
        "    self.seq_len = seq_len \n",
        "    self.n_layers = n_layers \n",
        "    self.rnn = nn.RNN(n_features, n_hidden, n_layers, batch_first = True)\n",
        "    self.fc = nn.Sequential(nn.Linear(n_hidden * seq_len, out_features=1), nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def reset_hidden_state(self):\n",
        "    self.hidden_layer = (\n",
        "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n",
        "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n",
        "    )\n",
        "\n",
        "  def forward(self, seq): # sequences: 1 X time X features\n",
        "    seq = torch.unsqueeze(seq, 0) # 3차원으로 만듦\n",
        "    ho = torch.zeros(self.n_layers, seq.size()[0], self.n_hidden) #seq : [x1~x30] : sequence     Times X Features\n",
        "    out, _ = self.rnn(seq, ho) # out: RNN의 마지막 레이어로부터 나온 output feature 를 반환한다. hn: hidden state를 반환한다.\n",
        "    out = out.reshape(out.shape[0], -1) # many to many 전략\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "QA37eW4N-U-u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(one, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(one.shape[0]-seq_length):\n",
        "        x = one.iloc[i:(i+seq_length)]\n",
        "        y = one.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(one, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(one)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=one.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ga-QNw-YmH",
        "outputId": "5dd34cd9-86c1-4748-f7fa-e6c8e0257584"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 51.507%, val loss: 49.919%\n",
            "Epoch 10 train loss: 49.924%, val loss: 49.822%\n",
            "Epoch 20 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 30 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 40 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 50 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 60 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 70 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 80 train loss: 49.924%, val loss: 49.821%\n",
            "Epoch 90 train loss: 49.924%, val loss: 49.821%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjpY7oU7Ifw7",
        "outputId": "b5cbd008-02e2-4cb6-d668-a0cc4ae62982"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  2.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# two['납품요구접수일자'] =  pd.to_datetime(two['납품요구접수일자'])\n",
        "# two = two.set_index('납품요구접수일자')\n",
        "# two = two.set_index('납품요구접수일자')"
      ],
      "metadata": {
        "id": "aww80jZi-ydh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#월, 년, 주 구하기\n",
        "\n",
        "two['month'] = two.index.month\n",
        "two['year'] = two.index.year\n",
        "two['dayofweek'] = two.index.dayofweek"
      ],
      "metadata": {
        "id": "Mg-ZeLK8ALyO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(two, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(two.shape[0]-seq_length):\n",
        "        x = two.iloc[i:(i+seq_length)]\n",
        "        y = two.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(two, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(two)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=two.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQrbh2_yAZtF",
        "outputId": "21f35f55-13de-465e-e7c1-207d2b7b3e62"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 54.682%, val loss: 49.808%\n",
            "Epoch 10 train loss: 49.619%, val loss: 48.913%\n",
            "Epoch 20 train loss: 49.506%, val loss: 48.905%\n",
            "Epoch 30 train loss: 49.458%, val loss: 48.903%\n",
            "Epoch 40 train loss: 49.434%, val loss: 48.902%\n",
            "Epoch 50 train loss: 49.421%, val loss: 48.902%\n",
            "Epoch 60 train loss: 49.414%, val loss: 48.902%\n",
            "Epoch 70 train loss: 49.411%, val loss: 48.902%\n",
            "Epoch 80 train loss: 49.409%, val loss: 48.901%\n",
            "Epoch 90 train loss: 49.407%, val loss: 48.901%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or8nAWbYJVOH",
        "outputId": "947e23da-c5f5-4c72-98d6-594a8fd967b6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  1.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# three['납품요구접수일자'] =  pd.to_datetime(three['납품요구접수일자'])\n",
        "# three = three.set_index('납품요구접수일자')\n",
        "# three = three.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "three['month'] = three.index.month\n",
        "three['year'] = three.index.year\n",
        "three['dayofweek'] = three.index.dayofweek"
      ],
      "metadata": {
        "id": "0LWceYtpAt3m"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(three, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(three.shape[0]-seq_length):\n",
        "        x = three.iloc[i:(i+seq_length)]\n",
        "        y = three.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(three, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(three)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=three.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nc9o70tCKm-",
        "outputId": "15742aa1-ecbf-4548-a264-eaee6bb167ff"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 61.333%, val loss: 73.122%\n",
            "Epoch 10 train loss: 51.870%, val loss: 70.631%\n",
            "Epoch 20 train loss: 51.799%, val loss: 70.425%\n",
            "Epoch 30 train loss: 51.781%, val loss: 70.335%\n",
            "Epoch 40 train loss: 51.774%, val loss: 70.283%\n",
            "Epoch 50 train loss: 51.770%, val loss: 70.249%\n",
            "Epoch 60 train loss: 51.769%, val loss: 70.225%\n",
            "Epoch 70 train loss: 51.767%, val loss: 70.209%\n",
            "Epoch 80 train loss: 51.767%, val loss: 70.197%\n",
            "Epoch 90 train loss: 51.766%, val loss: 70.190%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfNnusbRJmIw",
        "outputId": "c7a1c068-405d-4746-d8e2-dfd86985394d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  1.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# four['납품요구접수일자'] =  pd.to_datetime(four['납품요구접수일자'])\n",
        "# four = four.set_index('납품요구접수일자')\n",
        "# four = four.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "four['month'] = four.index.month\n",
        "four['year'] = four.index.year\n",
        "four['dayofweek'] = four.index.dayofweek"
      ],
      "metadata": {
        "id": "u9RnP9YHCdTV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(four, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(four.shape[0]-seq_length):\n",
        "        x = four.iloc[i:(i+seq_length)]\n",
        "        y = four.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(four, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(four)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=four.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33w5ozoyDANu",
        "outputId": "b2e0b2d8-30d9-44ab-d103-f0296d385fef"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 52.749%, val loss: 49.843%\n",
            "Epoch 10 train loss: 49.203%, val loss: 48.721%\n",
            "Epoch 20 train loss: 49.111%, val loss: 48.653%\n",
            "Epoch 30 train loss: 49.085%, val loss: 48.633%\n",
            "Epoch 40 train loss: 49.075%, val loss: 48.625%\n",
            "Epoch 50 train loss: 49.072%, val loss: 48.621%\n",
            "Epoch 60 train loss: 49.071%, val loss: 48.620%\n",
            "Epoch 70 train loss: 49.070%, val loss: 48.619%\n",
            "Epoch 80 train loss: 49.070%, val loss: 48.619%\n",
            "Epoch 90 train loss: 49.070%, val loss: 48.618%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLn3OwzVJnU4",
        "outputId": "53613ed9-ed95-4208-d7ea-8ce75127d9af"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  1.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# five['납품요구접수일자'] =  pd.to_datetime(five['납품요구접수일자'])\n",
        "# five = five.set_index('납품요구접수일자')\n",
        "# five = five.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "five['month'] = five.index.month\n",
        "five['year'] = five.index.year\n",
        "five['dayofweek'] = five.index.dayofweek"
      ],
      "metadata": {
        "id": "AvLSqEq0DK0G"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(five, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(five.shape[0]-seq_length):\n",
        "        x = five.iloc[i:(i+seq_length)]\n",
        "        y = five.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(five, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(five)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=five.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IS3scNQETAV",
        "outputId": "c6a0b806-aa5a-4124-915c-f337cf3eaa58"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 73.142%, val loss: 64.118%\n",
            "Epoch 10 train loss: 53.428%, val loss: 44.058%\n",
            "Epoch 20 train loss: 52.391%, val loss: 43.263%\n",
            "Epoch 30 train loss: 52.136%, val loss: 43.072%\n",
            "Epoch 40 train loss: 52.033%, val loss: 42.999%\n",
            "Epoch 50 train loss: 51.981%, val loss: 42.964%\n",
            "Epoch 60 train loss: 51.951%, val loss: 42.946%\n",
            "Epoch 70 train loss: 51.933%, val loss: 42.935%\n",
            "Epoch 80 train loss: 51.922%, val loss: 42.928%\n",
            "Epoch 90 train loss: 51.915%, val loss: 42.924%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34H_JeGbJowG",
        "outputId": "de10ffbf-f031-4c2e-8e82-0d693c911de9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  1.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# six['납품요구접수일자'] =  pd.to_datetime(six['납품요구접수일자'])\n",
        "# six = six.set_index('납품요구접수일자')\n",
        "# six = six.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "six['month'] = six.index.month\n",
        "six['year'] = six.index.year\n",
        "six['dayofweek'] = six.index.dayofweek"
      ],
      "metadata": {
        "id": "Kg4gOn4LEfwt"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(six, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(six.shape[0]-seq_length):\n",
        "        x = six.iloc[i:(i+seq_length)]\n",
        "        y = six.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(six, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(six)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=six.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVYt-eDAGkT1",
        "outputId": "cb0382b0-60a2-4073-bec0-9f1965b7752e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 52.099%, val loss: 52.735%\n",
            "Epoch 10 train loss: 50.116%, val loss: 52.459%\n",
            "Epoch 20 train loss: 50.055%, val loss: 52.419%\n",
            "Epoch 30 train loss: 50.044%, val loss: 52.410%\n",
            "Epoch 40 train loss: 50.042%, val loss: 52.409%\n",
            "Epoch 50 train loss: 50.041%, val loss: 52.408%\n",
            "Epoch 60 train loss: 50.041%, val loss: 52.408%\n",
            "Epoch 70 train loss: 50.041%, val loss: 52.408%\n",
            "Epoch 80 train loss: 50.041%, val loss: 52.408%\n",
            "Epoch 90 train loss: 50.041%, val loss: 52.408%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N4r13hNJpnG",
        "outputId": "1e812ce0-04d0-4397-9564-a7c96f8317fb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seven['납품요구접수일자'] =  pd.to_datetime(seven['납품요구접수일자'])\n",
        "# seven = seven.set_index('납품요구접수일자')\n",
        "# seven = seven.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "seven['month'] = seven.index.month\n",
        "seven['year'] = seven.index.year\n",
        "seven['dayofweek'] = seven.index.dayofweek"
      ],
      "metadata": {
        "id": "MINPOEZsHDWn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(seven, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(seven.shape[0]-seq_length):\n",
        "        x = seven.iloc[i:(i+seq_length)]\n",
        "        y = seven.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(seven, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(seven)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=seven.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0rlP_2HO-l",
        "outputId": "c4d5065e-c5f2-48c7-c263-0e6b1afc2dbe"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 50.708%, val loss: 49.604%\n",
            "Epoch 10 train loss: 49.091%, val loss: 49.290%\n",
            "Epoch 20 train loss: 49.090%, val loss: 49.277%\n",
            "Epoch 30 train loss: 49.089%, val loss: 49.274%\n",
            "Epoch 40 train loss: 49.089%, val loss: 49.274%\n",
            "Epoch 50 train loss: 49.089%, val loss: 49.274%\n",
            "Epoch 60 train loss: 49.089%, val loss: 49.273%\n",
            "Epoch 70 train loss: 49.089%, val loss: 49.273%\n",
            "Epoch 80 train loss: 49.089%, val loss: 49.273%\n",
            "Epoch 90 train loss: 49.089%, val loss: 49.273%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMQ5M_zvHxkl",
        "outputId": "188c3b4b-ac27-47c1-8ec3-c4722ab0cedb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE :  1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eight['납품요구접수일자'] =  pd.to_datetime(eight['납품요구접수일자'])\n",
        "# eight = eight.set_index('납품요구접수일자')\n",
        "# eight = eight.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "eight['month'] = eight.index.month\n",
        "eight['year'] = eight.index.year\n",
        "eight['dayofweek'] = eight.index.dayofweek"
      ],
      "metadata": {
        "id": "blG9hKrnIX9t"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(eight, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(eight.shape[0]-seq_length):\n",
        "        x = eight.iloc[i:(i+seq_length)]\n",
        "        y = eight.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(eight, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(eight)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=eight.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " \n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJl4J3ngKwU-",
        "outputId": "558965e6-5339-4aeb-ef9c-9e059e32da8d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 51.726%, val loss: 49.958%\n",
            "Epoch 10 train loss: 50.373%, val loss: 49.801%\n",
            "Epoch 20 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 30 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 40 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 50 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 60 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 70 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 80 train loss: 50.372%, val loss: 49.801%\n",
            "Epoch 90 train loss: 50.372%, val loss: 49.801%\n",
            "RMSE :  2.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nine['납품요구접수일자'] =  pd.to_datetime(nine['납품요구접수일자'])\n",
        "# nine = nine.set_index('납품요구접수일자')\n",
        "# nine = nine.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "nine['month'] = nine.index.month\n",
        "nine['year'] = nine.index.year\n",
        "nine['dayofweek'] = nine.index.dayofweek"
      ],
      "metadata": {
        "id": "QkEW3KkqLJUe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(nine, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(nine.shape[0]-seq_length):\n",
        "        x = nine.iloc[i:(i+seq_length)]\n",
        "        y = nine.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(nine, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(nine)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=nine.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " \n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVJET8IQLU11",
        "outputId": "ec909c8f-88e6-408a-e446-456cfefb242a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 52.259%, val loss: 50.131%\n",
            "Epoch 10 train loss: 49.250%, val loss: 48.839%\n",
            "Epoch 20 train loss: 49.180%, val loss: 48.741%\n",
            "Epoch 30 train loss: 49.167%, val loss: 48.699%\n",
            "Epoch 40 train loss: 49.165%, val loss: 48.678%\n",
            "Epoch 50 train loss: 49.164%, val loss: 48.668%\n",
            "Epoch 60 train loss: 49.164%, val loss: 48.663%\n",
            "Epoch 70 train loss: 49.164%, val loss: 48.661%\n",
            "Epoch 80 train loss: 49.164%, val loss: 48.659%\n",
            "Epoch 90 train loss: 49.164%, val loss: 48.659%\n",
            "RMSE :  1.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ten['납품요구접수일자'] =  pd.to_datetime(ten['납품요구접수일자'])\n",
        "# ten = ten.set_index('납품요구접수일자')\n",
        "# ten = ten.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "ten['month'] = ten.index.month\n",
        "ten['year'] = ten.index.year\n",
        "ten['dayofweek'] = ten.index.dayofweek"
      ],
      "metadata": {
        "id": "6JnR_FEpMFv1"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(ten, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(ten.shape[0]-seq_length):\n",
        "        x = ten.iloc[i:(i+seq_length)]\n",
        "        y = ten.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(ten, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(ten)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=ten.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " \n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKTXQI47MeN1",
        "outputId": "b9b220b4-981e-495c-8020-056e68fd804e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 50.309%, val loss: 49.966%\n",
            "Epoch 10 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 20 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 30 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 40 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 50 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 60 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 70 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 80 train loss: 49.353%, val loss: 49.884%\n",
            "Epoch 90 train loss: 49.353%, val loss: 49.884%\n",
            "RMSE :  2.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eleven['납품요구접수일자'] =  pd.to_datetime(eleven['납품요구접수일자'])\n",
        "# eleven = eleven.set_index('납품요구접수일자')\n",
        "# eleven = eleven.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "eleven['month'] = eleven.index.month\n",
        "eleven['year'] = eleven.index.year\n",
        "eleven['dayofweek'] = eleven.index.dayofweek"
      ],
      "metadata": {
        "id": "CNRl8tYeN8o4"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(eleven, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(eleven.shape[0]-seq_length):\n",
        "        x = eleven.iloc[i:(i+seq_length)]\n",
        "        y = eleven.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(eleven, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(eleven)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=eleven.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " \n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kANG8qCWOAfu",
        "outputId": "b2f47de2-602a-41b1-ba22-d6c902b16516"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 53.237%, val loss: 53.254%\n",
            "Epoch 10 train loss: 51.928%, val loss: 53.144%\n",
            "Epoch 20 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 30 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 40 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 50 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 60 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 70 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 80 train loss: 51.927%, val loss: 53.144%\n",
            "Epoch 90 train loss: 51.927%, val loss: 53.144%\n",
            "RMSE :  2.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#twelve['납품요구접수일자'] =  pd.to_datetime(twelve['납품요구접수일자'])\n",
        "#twelve = twelve.set_index('납품요구접수일자')\n",
        "#twelve = twelve.set_index('납품요구접수일자')\n",
        "\n",
        "#월, 년, 주 구하기\n",
        "\n",
        "twelve['month'] = twelve.index.month\n",
        "twelve['year'] = twelve.index.year\n",
        "twelve['dayofweek'] = twelve.index.dayofweek"
      ],
      "metadata": {
        "id": "9vFAZB_qOXek"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#x와 y값 sequence형태로 만들기\n",
        "def create_sequences(twelve, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(twelve.shape[0]-seq_length):\n",
        "        x = twelve.iloc[i:(i+seq_length)]\n",
        "        y = twelve.iloc[i+seq_length, -1]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "seq_length = 10\n",
        "X, Y = create_sequences(twelve, seq_length)\n",
        "\n",
        "\n",
        "# 학습과 테스트 데이터 분리\n",
        "split_ratio = 0.8\n",
        "split = int(len(twelve)*split_ratio)\n",
        "\n",
        "# split\n",
        "X_train = X[:split]\n",
        "X_val = X[split:]\n",
        "Y_train = Y[:split]\n",
        "Y_val = Y[split:]\n",
        "\n",
        "# to tensor\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "Y_train = torch.from_numpy(Y_train).float()\n",
        "Y_val = torch.from_numpy(Y_val).float()\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_val, Y_val)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "model = BTCPredictor1(n_features=twelve.shape[1],\n",
        "                   n_hidden=4,\n",
        "                   seq_len=10,\n",
        "                   n_layers=1,\n",
        "                   )\n",
        "\n",
        "#underfitting, overfitting 확인\n",
        "model, train_hist, val_hist, val_preds, val_targets = train_model(\n",
        "    model,\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    X_val,\n",
        "    Y_val,\n",
        "    num_epochs=100,\n",
        "    verbose=10)\n",
        " \n",
        "# rmse(root mean square error)\n",
        "rmse = np.sqrt(MSE(val_targets, val_preds))\n",
        "print(\"RMSE : % .2f\" %(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WatHCw9P_9V",
        "outputId": "83527a6c-734a-4d5c-cb01-c96d9e5f4456"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: 51.932%, val loss: 51.586%\n",
            "Epoch 10 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 20 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 30 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 40 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 50 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 60 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 70 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 80 train loss: 50.937%, val loss: 51.513%\n",
            "Epoch 90 train loss: 50.937%, val loss: 51.513%\n",
            "RMSE :  2.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xnp78B6TQYdn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}